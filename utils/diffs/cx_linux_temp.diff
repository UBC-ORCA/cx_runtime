diff --git a/Kbuild b/Kbuild
index 464b34a08f51..2880b03fa60b 100644
--- a/Kbuild
+++ b/Kbuild
@@ -97,3 +97,4 @@ obj-$(CONFIG_SAMPLES)	+= samples/
 obj-$(CONFIG_NET)	+= net/
 obj-y			+= virt/
 obj-y			+= $(ARCH_DRIVERS)
+obj-y           += cx_sys/
diff --git a/arch/riscv/include/asm/asm-prototypes.h b/arch/riscv/include/asm/asm-prototypes.h
index 36b955c762ba..637cd642e6cc 100644
--- a/arch/riscv/include/asm/asm-prototypes.h
+++ b/arch/riscv/include/asm/asm-prototypes.h
@@ -24,6 +24,7 @@ DECLARE_DO_ERROR_INFO(do_trap_ecall_u);
 DECLARE_DO_ERROR_INFO(do_trap_ecall_s);
 DECLARE_DO_ERROR_INFO(do_trap_ecall_m);
 DECLARE_DO_ERROR_INFO(do_trap_break);
+DECLARE_DO_ERROR_INFO(do_trap_first_cx_use);
 
 asmlinkage void handle_bad_stack(struct pt_regs *regs);
 asmlinkage void do_page_fault(struct pt_regs *regs);
diff --git a/arch/riscv/include/asm/switch_to.h b/arch/riscv/include/asm/switch_to.h
index f90d8e42f3c7..b0d43e94c0dd 100644
--- a/arch/riscv/include/asm/switch_to.h
+++ b/arch/riscv/include/asm/switch_to.h
@@ -8,6 +8,7 @@
 
 #include <linux/jump_label.h>
 #include <linux/sched/task_stack.h>
+#include "../../../../../../../research/riscv-tools/cx_runtime/include/utils.h"
 #include <asm/vector.h>
 #include <asm/cpufeature.h>
 #include <asm/processor.h>
@@ -70,6 +71,26 @@ static __always_inline bool has_fpu(void) { return false; }
 #define __switch_to_fpu(__prev, __next) do { } while (0)
 #endif
 
+static inline void __switch_to_cx(struct task_struct *prev,
+				   struct task_struct *next)
+{
+	pr_info("old mcx_table_addr: %08x\n", &prev->mcx_table[0]);
+	/* Saving */
+    uint cx_sel_index = cx_csr_read(CX_INDEX);
+    prev->cx_index = cx_sel_index;
+	uint cx_error = cx_csr_read(CX_STATUS);
+    prev->cx_status = cx_error;
+
+	/* Restoring */
+	pr_info("new mcx_table_addr: %08x\n", &next->mcx_table[0]);
+
+	// csr_write(CX_STATUS, next->cx_status);
+    // csr_write(MCX_TABLE, &next->mcx_table[0]);
+    // csr_write( CX_INDEX, next->cx_index );
+
+	
+}
+
 extern struct task_struct *__switch_to(struct task_struct *,
 				       struct task_struct *);
 
@@ -81,6 +102,7 @@ do {							\
 		__switch_to_fpu(__prev, __next);	\
 	if (has_vector())					\
 		__switch_to_vector(__prev, __next);	\
+	__switch_to_cx(__prev, __next);         \
 	((last) = __switch_to(__prev, __next));		\
 } while (0)
 
diff --git a/arch/riscv/kernel/traps.c b/arch/riscv/kernel/traps.c
index a1b9be3c4332..9722f85d0c11 100644
--- a/arch/riscv/kernel/traps.c
+++ b/arch/riscv/kernel/traps.c
@@ -32,6 +32,8 @@
 #include <asm/vector.h>
 #include <asm/irq_stack.h>
 
+#include "../../../../research/riscv-tools/cx_runtime/include/utils.h"
+
 int show_unhandled_signals = 1;
 
 static DEFINE_SPINLOCK(die_lock);
@@ -113,7 +115,6 @@ void die(struct pt_regs *regs, const char *str)
 void do_trap(struct pt_regs *regs, int signo, int code, unsigned long addr)
 {
 	struct task_struct *tsk = current;
-
 	if (show_unhandled_signals && unhandled_signal(tsk, signo)
 	    && printk_ratelimit()) {
 		pr_info("%s[%d]: unhandled signal %d code 0x%x at 0x" REG_FMT,
@@ -169,6 +170,14 @@ DO_ERROR_INFO(do_trap_insn_fault,
 asmlinkage __visible __trap_section void do_trap_insn_illegal(struct pt_regs *regs)
 {
 	bool handled;
+	u32 insn = (u32)regs->badaddr;
+	uint opc = insn & ((1<<7)-1);
+
+	if (opc == CX_REG_TYPE || opc == CX_IMM_TYPE || opc == CX_FLEX_TYPE) {
+		do_trap_first_cx_use(regs);
+		return;
+	}
+
 
 	if (user_mode(regs)) {
 		irqentry_enter_from_user_mode(regs);
@@ -339,6 +348,23 @@ asmlinkage __visible __trap_section void do_trap_ecall_u(struct pt_regs *regs)
 
 }
 
+/* TODO (cx, Brandon): This is incredibly hacky - Used for virtualization of state. */
+asmlinkage __visible __trap_section void do_trap_first_cx_use(struct pt_regs *regs)
+{
+	long syscall = 461;
+
+	regs->orig_a0 = regs->a0;
+
+	riscv_v_vstate_discard(regs);
+
+	if (syscall >= 0 && syscall < NR_syscalls)
+		syscall_handler(regs, syscall);
+	else if (syscall != -1)
+		regs->a0 = -ENOSYS;
+
+	syscall_exit_to_user_mode(regs);
+}
+
 #ifdef CONFIG_MMU
 asmlinkage __visible noinstr void do_page_fault(struct pt_regs *regs)
 {
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 292c31697248..ef6a6d14af1b 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -39,6 +39,9 @@
 #include <linux/livepatch_sched.h>
 #include <asm/kmap_size.h>
 
+#include <linux/queue.h>
+#include "../../../../research/riscv-tools/cx_runtime/include/cx_kern_structs.h"
+
 /* task_struct member predeclarations (sorted alphabetically): */
 struct audit_context;
 struct bio_list;
@@ -1544,6 +1547,16 @@ struct task_struct {
 	struct user_event_mm		*user_event_mm;
 #endif
 
+	uint cx_status;
+	uint cx_index;
+	uint *mcx_table;
+	cx_os_state_t *cx_os_state_table;
+
+	queue_t *cx_table_avail_indices;
+
+	// TODO: This shouldn't be here - should be in the device_struct.
+	// cx_entry_t cx_map[NUM_CX];
+
 	/*
 	 * New fields for task_struct should be added above here, so that
 	 * they are included in the randomized portion of task_struct.
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index fd9d12de7e92..81ac5f3406be 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1279,4 +1279,11 @@ int __sys_getsockopt(int fd, int level, int optname, char __user *optval,
 		int __user *optlen);
 int __sys_setsockopt(int fd, int level, int optname, char __user *optval,
 		int optlen);
+
+long sys_cx_open(int cx_guid);
+long sys_cx_close(int cx_sel);
+// long __riscv_sys_context_restore(void);
+// long __riscv_sys_context_save(void);
+// long sys_cx_first_use(void);
+
 #endif
diff --git a/include/uapi/asm-generic/unistd.h b/include/uapi/asm-generic/unistd.h
index 756b013fb832..81e95ed4d5b2 100644
--- a/include/uapi/asm-generic/unistd.h
+++ b/include/uapi/asm-generic/unistd.h
@@ -828,9 +828,19 @@ __SYSCALL(__NR_futex_wake, sys_futex_wake)
 __SYSCALL(__NR_futex_wait, sys_futex_wait)
 #define __NR_futex_requeue 456
 __SYSCALL(__NR_futex_requeue, sys_futex_requeue)
+#define __NR_cx_open 457
+__SYSCALL(__NR_cx_open, sys_cx_open)
+#define __NR_cx_close 458
+__SYSCALL(__NR_cx_close, sys_cx_close)
+#define __NR_context_save 459
+__SYSCALL(__NR_context_save, sys_context_save)
+#define __NR_context_restore 460
+__SYSCALL(__NR_context_restore, sys_context_restore)
+#define __NR_do_nothing 461
+__SYSCALL(__NR_do_nothing, sys_do_nothing)
 
 #undef __NR_syscalls
-#define __NR_syscalls 457
+#define __NR_syscalls 462
 
 /*
  * 32 bit systems traditionally used different
diff --git a/init/init_task.c b/init/init_task.c
index 5727d42149c3..75eaae07bdf4 100644
--- a/init/init_task.c
+++ b/init/init_task.c
@@ -210,9 +210,15 @@ struct task_struct init_task
 #ifdef CONFIG_SECCOMP_FILTER
 	.seccomp	= { .filter_count = ATOMIC_INIT(0) },
 #endif
+.mcx_table = NULL,
+.cx_os_state_table = NULL,
+.cx_table_avail_indices = NULL,
 };
 EXPORT_SYMBOL(init_task);
 
+cx_entry_t cx_map[NUM_CX];
+EXPORT_SYMBOL(cx_map);
+
 /*
  * Initial thread structure. Alignment of this is handled by a special
  * linker map entry.
diff --git a/init/main.c b/init/main.c
index e24b0780fdff..d7deb2147b6b 100644
--- a/init/main.c
+++ b/init/main.c
@@ -111,6 +111,8 @@
 
 #include <kunit/test.h>
 
+#include <linux/kern_funcs.h>
+
 static int kernel_init(void *);
 
 /*
@@ -670,6 +672,7 @@ static void __init setup_command_line(char *command_line)
 	saved_command_line_len = strlen(saved_command_line);
 }
 
+
 /*
  * We need to finalize in a non-__init function or else race conditions
  * between the root thread and the init thread may cause start_kernel to
@@ -693,6 +696,7 @@ noinline void __ref __noreturn rest_init(void)
 	 * we schedule it before we create kthreadd, will OOPS.
 	 */
 	pid = user_mode_thread(kernel_init, NULL, CLONE_FS);
+
 	/*
 	 * Pin init on the boot CPU. Task migration is not properly working
 	 * until sched_init_smp() has been run. It will set the allowed
@@ -727,7 +731,9 @@ noinline void __ref __noreturn rest_init(void)
 	 */
 	schedule_preempt_disabled();
 	/* Call into cpu_idle with preempt disabled */
+
 	cpu_startup_entry(CPUHP_ONLINE);
+
 }
 
 /* Check for early params. */
@@ -1462,9 +1468,10 @@ static int __ref kernel_init(void *unused)
 	rcu_end_inkernel_boot();
 
 	do_sysctl_args();
-
 	if (ramdisk_execute_command) {
 		ret = run_init_process(ramdisk_execute_command);
+		cx_init();
+		pr_info("init pid: %d\n", current->pid);
 		if (!ret)
 			return 0;
 		pr_err("Failed to execute %s (error %d)\n",
diff --git a/kernel/exit.c b/kernel/exit.c
index aedc0832c9f4..ee4dbe32908d 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -75,6 +75,7 @@
 #include <asm/mmu_context.h>
 
 #include "exit.h"
+#include <linux/kern_funcs.h>
 
 /*
  * The default value should be high enough to not crash a system that randomly
@@ -851,6 +852,7 @@ void __noreturn do_exit(long code)
 	audit_free(tsk);
 
 	tsk->exit_code = code;
+	exit_cx(tsk);
 	taskstats_exit(tsk, group_dead);
 
 	exit_mm();
diff --git a/kernel/fork.c b/kernel/fork.c
index 10917c3e1f03..7404c5ff77b3 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -111,6 +111,8 @@
 #define CREATE_TRACE_POINTS
 #include <trace/events/task.h>
 
+#include <linux/kern_funcs.h>
+
 /*
  * Minimum number of threads to boot the kernel
  */
@@ -1112,6 +1114,7 @@ static struct task_struct *dup_task_struct(struct task_struct *orig, int node)
 		return NULL;
 
 	err = arch_dup_task_struct(tsk, orig);
+
 	if (err)
 		goto free_tsk;
 
@@ -1197,6 +1200,11 @@ static struct task_struct *dup_task_struct(struct task_struct *orig, int node)
 	tsk->mm_cid_active = 0;
 	tsk->migrate_from_cpu = -1;
 #endif
+
+	// tsk->cx_index = orig->cx_index;
+	// tsk->cx_status = orig->cx_status;
+	// cx_process_alloc(tsk);
+
 	return tsk;
 
 free_stack:
@@ -2332,6 +2340,7 @@ __latent_entropy struct task_struct *copy_process(
 	p = dup_task_struct(current, node);
 	if (!p)
 		goto fork_out;
+
 	p->flags &= ~PF_KTHREAD;
 	if (args->kthread)
 		p->flags |= PF_KTHREAD;
@@ -2391,6 +2400,7 @@ __latent_entropy struct task_struct *copy_process(
 	INIT_LIST_HEAD(&p->sibling);
 	rcu_copy_process(p);
 	p->vfork_done = NULL;
+
 	spin_lock_init(&p->alloc_lock);
 
 	init_sigpending(&p->pending);
@@ -2649,6 +2659,8 @@ __latent_entropy struct task_struct *copy_process(
 
 	rseq_fork(p, clone_flags);
 
+	// cx_init_process(p);
+
 	/* Don't start children in a dying pid namespace */
 	if (unlikely(!(ns_of_pid(pid)->pid_allocated & PIDNS_ADDING))) {
 		retval = -ENOMEM;
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index a708d225c28e..5653449fd8ea 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -95,6 +95,8 @@
 #include "../../io_uring/io-wq.h"
 #include "../smpboot.h"
 
+#include <linux/kern_funcs.h>
+
 EXPORT_TRACEPOINT_SYMBOL_GPL(ipi_send_cpu);
 EXPORT_TRACEPOINT_SYMBOL_GPL(ipi_send_cpumask);
 
@@ -5339,6 +5341,7 @@ context_switch(struct rq *rq, struct task_struct *prev,
 	 * switch_mm_cid() needs to be updated if the barriers provided
 	 * by context_switch() are modified.
 	 */
+	// int cx_flag = 0;
 	if (!next->mm) {                                // to kernel
 		enter_lazy_tlb(prev->active_mm, next);
 
@@ -5364,16 +5367,23 @@ context_switch(struct rq *rq, struct task_struct *prev,
 			/* will mmdrop_lazy_tlb() in finish_task_switch(). */
 			rq->prev_mm = prev->active_mm;
 			prev->active_mm = NULL;
-		}
+		} 
+		// else {
+		// 	cx_context_save(prev);
+		// 	// cx_context_restore(next);
+		// 	// cx_flag = 1;
+		// }
 	}
 
 	/* switch_mm_cid() requires the memory barriers above. */
 	switch_mm_cid(rq, prev, next);
 
 	prepare_lock_switch(rq, next, rf);
+	// csr_write(MCX_TABLE, &next->mcx_table[0]);
 
 	/* Here we just switch the register state and the stack. */
 	switch_to(prev, next, prev);
+
 	barrier();
 
 	return finish_task_switch(prev);
diff --git a/lib/Makefile b/lib/Makefile
index 6b09731d8e61..1268a6f201a7 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -411,6 +411,9 @@ obj-$(CONFIG_GENERIC_LIB_DEVMEM_IS_ALLOWED) += devmem_is_allowed.o
 
 obj-$(CONFIG_FIRMWARE_TABLE) += fw_table.o
 
+obj-y += queue.o
+obj-y += kern_funcs.o
+
 # FORTIFY_SOURCE compile-time behavior tests
 TEST_FORTIFY_SRCS = $(wildcard $(srctree)/$(src)/test_fortify/*-*.c)
 TEST_FORTIFY_LOGS = $(patsubst $(srctree)/$(src)/%.c, %.log, $(TEST_FORTIFY_SRCS))
